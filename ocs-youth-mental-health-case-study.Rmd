---
title: "Open Case Studies : Youth Mental Health "
output:
  html_document:
    self_contained: yes
    code_download: yes
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes

---
<style>
#TOC {
  background: url("https://opencasestudies.github.io/img/logo.jpg");
  background-size: contain;
  padding-top: 240px !important;
  background-repeat: no-repeat;
}
</style>

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**CSS not mentioned in metadata**

</div>

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE, cache = FALSE,
                      fig.align = "center", out.width = '90%')
library(here)
library(knitr)
library(magick)
```

## {.disclaimer_block}

**Disclaimer**: The purpose of the [Open Case Studies](https://opencasestudies.github.io){target="_blank"} project is **to demonstrate the use of various data science methods, tools, and software in the context of messy, real-world data**. A given case study does not cover all aspects of the research process, is not claiming to be the most appropriate way to analyze a given data set, and should not be used in the context of making policy decisions without external consultation from scientific experts. 


## {.license_block}

This work is licensed under the Creative Commons Attribution-NonCommercial 3.0 [(CC BY-NC 3.0)](https://creativecommons.org/licenses/by-nc/3.0/us/){target="_blank"}  United States License.

## **Motivation**
*** 

The following paper motivated this case study. 

#### {.reference_block}

Twenge JM, Cooper AB, Joiner TE, Duffy ME, Binau SG. Age, period, and cohort trends in mood disorder indicators and suicide-related outcomes in a nationally representative dataset, 2005-2017. *J Abnorm Psychol*. 2019;128(3):185-199. doi:10.1037/abn0000410

## **Main Questions**
*** 

#### {.main_question_block}
<b><u> Our main questions: </u></b>

1) How have depression rates in American youth changed since 2002 (SAMHSA data).  
2) Do mental health services appear to be reaching more youths? How have rates differed between different youth subgroups (gender, ethnicity)?

####

## **Learning Objectives** 
*** 

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**May need to update this section to update the tidyverse packages included.**

</div>

In this case study, we will determine the percent of youth in America that have had a major depressive episode in the past year since 2002. We will compare how different youth subgroups have changed over time (by age group (12-13,14-15, and 16-17), gender, ethnicity).
We will especially focus on using packages and functions from the [`Tidyverse`](https://www.tidyverse.org/){target="_blank"}, such as [`rvest`](https://github.com/tidyverse/rvest). The tidyverse is a library of packages created by RStudio. While some students may be familiar with previous R programming packages, these packages make data science in R especially efficient.

```{r, out.width = "20%", echo = FALSE, fig.align ="center"}
include_graphics("https://tidyverse.tidyverse.org/logo.png")
```

*** 

We will begin by loading the packages that we will need:

```{r}
library(here)
library(tidyverse)
library(rvest)
```

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**I made some modifications to the table below. The `tidyverse` package hyperlink referenced `readr`. I thought this was incorrect. I changed this to the tidyverse website and provided a different description. If this was indeed a typo, it may need to be fixed in other case studies.**

</div>

 Package   | Use                                                                         
---------- |-------------
[here](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data
[tidyverse](https://www.tidyverse.org/){target="_blank"}      | R packages for data science
[rvest](https://github.com/tidyverse/rvest){target="_blank"}      | to scrape web pages

The first time we use a function, we will use the `::` to indicate which package we are using. Unless we have overlapping function names, this is not necessary, but we will include it here to be informative about where the functions we will use come from.

## **Context**
*** 

## **Limitations**
*** 

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**Perhaps "underestimates in the p-values..." is not the correct way to phrase this. I would look for a better way to word this.**

</div>

There are some important considerations regarding this data analysis to keep in mind: 

1) We treat sample estimates as observed values. This produces understimates in the p-values of statistical tests conducted.

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**Also: what other limitations exist?**

</div>

2) Limitition 2  

## **What are the data?**
*** 

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**I removed this section because the tables are relatively self-explatory. I am not sure exactly what should be in place of the table I removed.**

</div>

## **Data Import**
*** 

Define web scraping [according to Wikipedia](https://en.wikipedia.org/wiki/Web_scraping?oldformat=true)

There are two main steps to web scraping.

1. identify location of data that will be scraped

2. save scraped data to an object

`rvest` can be thought of as the `pdftools` package for webscraping. Upon pulling the data, additional wrangling will likely be required; like the `pdftools` package, `rvest` streamlines the extraction process.  

The two steps can be broken down even further 

1. identify location of data that will be scraped
    + right-click to inspect element (webpage)
    + hover pointer over components of element (webpage) until the data has been found
    + copy Xpath of data sought
2. save scraped data to an object
    + import html code for element (webpage)
    + extract pieces (table) out of HTML documents (webpage) using Xpath
    + parse the html table into a data frame
    
We accomplish STEP 1 with our web browser.

We accomplish STEP 2 in the `R` programming environment. 

Below is a animated overview of the process.

```{r, eval=FALSE, echo=FALSE}
step1 <- image_read(here("webpage_screenshot.png"))
step2 <- image_read(here("table_screenshot_inspect.png"))
step3 <- image_read(here("table_screenshot_inspect_table.png"))
step4 <- image_read(here("table_screenshot_inspect_table_xpath.png"))
step5 <- image_read(here("table_screenshot_xpath_copy_r.png"))
step5_zoom <- image_read(here("table_screenshot_xpath_copy_r_zoom.png"))

image_info(step5_zoom)

step5_zoom <- image_border(step5_zoom, "white", "284x334")

img <- c(step1,
         step2,
         step2,
         step3,
         step3,
         step4,
         step4,
         step5,
         step5,
         step5_zoom,
         step5_zoom,
         step5_zoom,
         step1)

educational_gif <- image_resize(img, '1440x900!') %>%
  image_background('white') %>%
  image_morph(frames = 10) %>%
  image_animate(delay = 20,
                optimize = TRUE)

image_write(educational_gif, "educational.gif")
```

```{r, echo=FALSE}
image_read(here("educational.gif"))
```

[Let's go to the web page with all the tables we are interested in scraping.](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm)

INSERT SCREENSHOT

Once on the webpage, there aren't any visible options to download the data. Usually, a delimited text file is available on the page. On the webpage above, no option exists. 

How do we proceed?

Right-click and select "Inspect" 

INSERT SCREENSHOT

A window opens. 

This window allows us to glance at the internal mechanics of the webpage. To scrape the data from the webpage, we need to first learn a little bit about the components that make it thet web page it is. 

Hovering our mouse over the elements of the webpage highlights the respective section of the webpage it represents. By hovering over several elements—and opening elements when the highlighted portion is too large—we can indentify the element that contains the data we are looking for. 

INSERT SCREENSHOT

Right click on the element and copy the XPath. We will need this XPath for the next step.

**Save scraped data to an object** 

For the first question we intend to answer, the XPath is `/html/body/div[4]/div[1]/table`. We use this Xpath with functions from the `rvest` package to scrape data from the web.

```{r}
url11.1a <- "https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm"
table11.1a <- url11.1a %>%
  read_html() %>%
  html_nodes(xpath='/html/body/div[4]/div[1]/table') %>%
  html_table()
table11.1a <- table11.1a[[1]]
```

```{r}
scraper <- function(XPATH){
  url <- "https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm"
  table <- url %>%
  read_html() %>%
  html_nodes(xpath=XPATH) %>%
  html_table()
  output <- table[[1]]
  output
}
```

```{r}
table11.1b <- scraper(XPATH = "/html/body/div[4]/div[2]/table")
table11.2a <- scraper(XPATH = '/html/body/div[4]/div[3]/table')
table11.2b <- scraper(XPATH = '/html/body/div[4]/div[4]/table')
table11.3a <- scraper(XPATH = '/html/body/div[4]/div[5]/table')
table11.3b <- scraper(XPATH = '/html/body/div[4]/div[6]/table')
table11.4a <- scraper(XPATH = '/html/body/div[4]/div[7]/table')
table11.4b <- scraper(XPATH = '/html/body/div[4]/div[8]/table')
```

## **Data Exploration and Wrangling**
*** 

Now that we've imported the data, let's see if we can wrangle a table. Since the data comes from a source that is well-maintained, it is likely that whatever steps we take to wrangle this first table will also be necessary in the wrangling of subsequent tables. This is because well-maintained data sources often format different datasets similarly. We can take advantage of this similarity to speed up the wrangling process. 

We will start with *Table 11.1a—Settings Where Mental Health Services Were Received in Past Year among Persons Aged 12 to 17: Numbers in Thousands, 2002-2018*.

**Table11.1a**

```{r}
dim(table11.1a)

table11.1a <- table11.1a[-dim(table11.1a)[1],]

table11.1a <- table11.1a %>%
  na_if("nc") %>%
  na_if("--") %>%
  na_if("") %>%
  na_if("*")

table11.1a <- table11.1a %>%
  as_tibble() %>%
  rename(MHS_setting = `Setting Where Mental Health ServiceWas Received`)

partA <- table11.1a %>%
  dplyr::select(MHS_setting)

partB <- table11.1a %>%
  dplyr::select(-MHS_setting)

partA <- partA %>%
  mutate(MHS_setting = gsub("[[:digit:]]+|[\r\n]|[[:punct:]]|([[:blank:]])\\1+",
                            "",
                            MHS_setting))

partB <- partB %>%
  mutate_all(str_remove_all, "a") %>%
  mutate_all(str_remove_all, ",")

rm(table11.1a)

table11.1a <- bind_cols(partA,
                        partB)

table11.1a <- table11.1a %>%
  pivot_longer(cols = contains("20"), names_to = "Year", values_to = "Number")

table11.1a <- table11.1a %>%
  filter(MHS_setting != "General Medicine") %>%
  filter(MHS_setting != "Juvenile Justice") #Leading lines with no data

table11.1a <- table11.1a %>%
  mutate_at(vars(Year, Number), as.numeric)
```

We will write a function to simplify this process.

The function needs to:

- remove the last row of the table
- get rid of certain patterns
- transition the data to long format

```{r}
data_prep_settings <- function(TABLE, old_col, new_col, pivot_col){
  TABLE <- TABLE[-dim(TABLE)[1],]
  TABLE <- TABLE %>%
  na_if("nc") %>%
  na_if("--") %>%
  na_if("") %>%
  na_if("*")
  TABLE <- TABLE %>%
    as_tibble() %>%
    rename({{new_col}} := {{old_col}})
  partA <- TABLE %>%
    dplyr::select({{new_col}})
  partB <- TABLE %>%
    dplyr::select(-{{new_col}})
  partA <- partA %>%
  mutate({{new_col}} := partA %>%
           dplyr::select({{new_col}}) %>%
           pull({{new_col}}) %>%
           gsub("[[:digit:]]+|[\r\n]|[[:punct:]]|([[:blank:]])\\1+",
                        "", .))
  partB <- partB %>%
    mutate_all(str_remove_all, "a") %>%
    mutate_all(str_remove_all, ",")
  rm(TABLE)
  TABLE <- bind_cols(partA,
                     partB)
  TABLE <- TABLE %>%
  pivot_longer(cols = contains("20"), names_to = "Year", values_to = pivot_col)
  TABLE
}
```

We then apply this function to the table, ridding the table of headings and ensuring some of our commons are correctly of numeric class.

```{r}
dim(table11.1b)

table11.1b <- data_prep_settings(TABLE = table11.1b,
          old_col = "Setting Where Mental Health ServiceWas Received",
          new_col = "MHS_setting",
          pivot_col = "Percent")

table11.1b <- table11.1b %>%
  filter(MHS_setting != "General Medicine") %>%
  filter(MHS_setting != "Juvenile Justice") #Leading lines with no data

table11.1b <- table11.1b %>%
  mutate_at(vars(Year, Percent), as.numeric)
```

We write a function to simplify this process for data that uses demographic groups as units of observation.

The function needs to:

- remove the last row of the table
- get rid of certain patterns
- transition the data to long format

```{r}
data_prep_dem <- function(TABLE, old_col, new_col, pivot_col){
  TABLE <- TABLE[-dim(TABLE)[1],]
  TABLE <- TABLE %>%
  na_if("nc") %>%
  na_if("--") %>%
  na_if("") %>%
  na_if("*")
  TABLE <- TABLE %>%
    as_tibble() %>%
    rename({{new_col}} := {{old_col}})
  partA <- TABLE %>%
    dplyr::select({{new_col}})
  partB <- TABLE %>%
    dplyr::select(-{{new_col}})
  partA <- partA %>%
  mutate({{new_col}} := partA %>%
           dplyr::select({{new_col}}) %>%
           pull({{new_col}}) %>%
           gsub("[\r\n]|[[:punct:]]|([[:blank:]])\\1+",
                        "", .))
  partA <- partA %>%
  mutate({{new_col}} := case_when(str_detect(!!as.name(new_col), pattern = "1") ~ paste("Age",
                                                        str_sub(!!as.name(new_col),
                                                                start = 1,
                                                                end =2),
                                                        str_sub(!!as.name(new_col),
                                                                start = 3,
                                                                end = 4),
                                                        sep="_"),
                                 TRUE ~ !!as.name(new_col)))
  partB <- partB %>%
    mutate_all(str_remove_all, "a") %>%
    mutate_all(str_remove_all, ",")
  rm(TABLE)
  TABLE <- bind_cols(partA,
                     partB)
  TABLE <- TABLE %>%
  pivot_longer(cols = contains("20"), names_to = "Year", values_to = pivot_col)
  TABLE
}
```

**Table11.2a**

We use the produced function to wrangle the next pair of tables. 

```{r}
dim(table11.2a)

table11.2a <- data_prep_dem(TABLE = table11.2a,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Number")

table11.2a %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.2a <- table11.2a %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.2a <- table11.2a %>%
  mutate_at(vars(Year, Number), as.numeric)
```

**Table11.2b**

```{r}
dim(table11.2b)

table11.2b <- data_prep_dem(TABLE = table11.2b,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Percent")

table11.2b %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.2b <- table11.2b %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.2b <- table11.2b %>%
  mutate_at(vars(Year, Percent), as.numeric)
```

We repeat this process for the remaining tables.

*Table 11.3a*

```{r}
dim(table11.3a)

table11.3a <- data_prep_dem(TABLE = table11.3a,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Number")

table11.3a %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.3a <- table11.3a %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.3a <- table11.3a %>%
  mutate_at(vars(Year, Number), as.numeric)
```

*Table 11.3b*

```{r}
dim(table11.3b)

table11.3b <- data_prep_dem(TABLE = table11.3b,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Percent")

table11.3b %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.3b <- table11.3b %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.3b <- table11.3b %>%
  mutate_at(vars(Year, Percent), as.numeric)
```

*Table 11.4a*

```{r}
dim(table11.4a)

table11.4a <- data_prep_dem(TABLE = table11.4a,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Number")

table11.4a %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.4a <- table11.4a %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.4a <- table11.4a %>%
  mutate_at(vars(Year, Number), as.numeric)
```

*Table 11.4b*

```{r}
dim(table11.4b)

table11.4b <- data_prep_dem(TABLE = table11.4b,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Percent")

table11.4b %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.4b <- table11.4b %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.4b <- table11.4b %>%
  mutate_at(vars(Year, Percent), as.numeric)
```

Now that we've wrangled the data, we can go ahead and proceed with our analysis. 

## **Data Analysis**
*** 

We would like to conduct a [chi-square test](https://en.wikipedia.org/wiki/Chi-squared_test?oldformat=true) for independence. 

To conduct this statistical test, we need to produce a 2x2 table.

```{r}
chi_square_11.2a <- table11.2a %>%
  filter(Year %in% c(2009, 2018)) %>%
  filter(Demographic %in% c("Male","Female")) %>%
  mutate(Number = Number * 1000)

chi_square_11.2a <- chi_square_11.2a %>%
  pivot_wider(names_from = Year,
              names_prefix = "Year", 
              values_from = Number) %>%
  column_to_rownames("Demographic")

chi_square_11.2a
```

```{r}
chisq.test(chi_square_11.2a)
```

```{r}
chi_square_11.3a <- table11.3a %>%
  filter(Year %in% c(2009, 2018)) %>%
  filter(Demographic %in% c("Male","Female")) %>%
  mutate(Number = Number * 1000)

chi_square_11.3a <- chi_square_11.3a %>%
  pivot_wider(names_from = Year,
              names_prefix = "Year", 
              values_from = Number) %>%
  column_to_rownames("Demographic")

chi_square_11.3a
```

```{r}
chisq.test(chi_square_11.3a)
```

```{r}
chi_square_11.4a <- table11.4a %>%
  filter(Year %in% c(2009, 2018)) %>%
  filter(Demographic %in% c("Male","Female")) %>%
  mutate(Number = Number * 1000)

chi_square_11.4a <- chi_square_11.4a %>%
  pivot_wider(names_from = Year,
              names_prefix = "Year", 
              values_from = Number) %>%
  column_to_rownames("Demographic")

chi_square_11.4a
```

```{r}
chisq.test(chi_square_11.4a)
```

## **Data Visualization**
*** 

```{r}
table11.1b %>%
  ggplot(aes(x = Year, y = Percent, group = MHS_setting)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  labs(title = "Settings Where Mental Health Services Were Received in Past Year\namong Persons Aged 12 to 17",
       subtitle = "Percentages, 2002-2018")
```

```{r}
table11.2b %>%
  ggplot(aes(x = Year, y = Percent, group = Demographic)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  labs(title = "Major Depressive Episode in Past Year\namong Persons Aged 12 to 17",
       subtitle = "By Demographic Characteristics, Percentages, 2004-2018")
```

```{r}
table11.3b %>%
  ggplot(aes(x = Year, y = Percent, group = Demographic)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  labs(title = "Major Depressive Episode with Severe Impairment in Past Year\namong Persons Aged 12 to 17",
       subtitle = "By Demographic Characteristics: Percentages, 2006-2018")
```

```{r}
table11.4b %>%
  ggplot(aes(x = Year, y = Percent, group = Demographic)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) + 
  labs(title = "Receipt of Treatment for Depression in Past Year among\nPersons Aged 12 to 17 with Major Depressive Episode in Past Year",
       subtitle = "By Demographic Characteristics: Percentages, 2004-2018")
```

## **Summary**
*** 

## **Suggested Homework**
*** 

## **Helpful Links**
*** 

**This needs to be updated**

[guide](https://briatte.github.io/ggcorr/) for using GGally to create correlation plots

<u>Terms and concepts covered:</u>  

[Tidyverse](https://www.tidyverse.org/){target="_blank"}  
[RStudio cheatsheets](https://rstudio.com/resources/cheatsheets/){target="_blank"}  

<u>Packages used in this case study: </u>

 Package   | Use                                                                         
---------- |-------------
[here](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data 
[tidyverse](https://www.tidyverse.org/){target="_blank"}      | R packages for data science
[rvest](https://github.com/tidyverse/rvest){target="_blank"}      | to scrape web pages

## **RA Notes**

[This is the motivating article for this case study](https://pubmed.ncbi.nlm.nih.gov/30869927/). In this article, they web scrape to obtain the data they need. 

[Here is the Lieber Institute's resource on web scrape](http://research.libd.org/rstatsclub/post/introduction-to-scraping-and-wranging-tables-from-research-articles/#.Xw878ZNKhQJ)

[Here is a resouce the Lieber Institute source above referse to](http://blog.corynissen.com/2015/01/using-rvest-to-scrape-html-table.html)

[Here as a good resource to learn how to web scrape](https://rstudio-pubs-static.s3.amazonaws.com/266430_f3fd4660b2744751ab144aa130768a06.html)

[This is the set of tables we would like to consider](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm)
