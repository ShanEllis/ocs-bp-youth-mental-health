---
title: "Open Case Studies : Mental Health of American Youth"
css: style.css
output:
  html_document:
    self_contained: yes
    code_download: yes
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes

---
<style>
#TOC {
  background: url("https://opencasestudies.github.io/img/logo.jpg");
  background-size: contain;
  padding-top: 240px !important;
  background-repeat: no-repeat;
}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE, cache = FALSE,
                      fig.align = "center", out.width = '90%')
library(here)
library(knitr)
library(magick)
```

## {.disclaimer_block}

**Disclaimer**: The purpose of the [Open Case Studies](https://opencasestudies.github.io){target="_blank"} project is **to demonstrate the use of various data science methods, tools, and software in the context of messy, real-world data**. A given case study does not cover all aspects of the research process, is not claiming to be the most appropriate way to analyze a given data set, and should not be used in the context of making policy decisions without external consultation from scientific experts. 

## {.license_block}

This work is licensed under the Creative Commons Attribution-NonCommercial 3.0 [(CC BY-NC 3.0)](https://creativecommons.org/licenses/by-nc/3.0/us/){target="_blank"}  United States License.

## {.reference_block}

To cite this case study please use:

Wright, Carrie, and Ontiveros, Michael and Jager, Leah and Taub, Margaret and Hicks, Stephanie. (2020). https://github.com/opencasestudies/ocs-bp-co2-emissions. Mental Health of American Youth (Version v1.0.0).


## **Motivation**
*** 

The following papers motivated this case study. 

#### {.reference_block}

Twenge JM, Cooper AB, Joiner TE, Duffy ME, Binau SG. Age, period, and cohort trends in mood disorder indicators and suicide-related outcomes in a nationally representative dataset, 2005-2017. *J Abnorm Psychol*.128,3 (2019):185-199. doi:10.1037/abn0000410


Olfson, M., Blanco, C., Wang, S., Laje, G. & Correll, C. U. National Trends in the Mental Health Care of Children, Adolescents, and Adults by Office-Based Physicians. *JAMA Psychiatry*. 71, 81 (2014):81-90. doi: 10.1001/jamapsychiatry.2013.3074.

####

The main findings of the first [article](https://content.apa.org/record/2019-12578-001){target="_blank"} are:

>Rates of major depressive episode in the last year increased 52% 2005–2017 (from 8.7% to 13.2%) among adolescents aged 12 to 17 and 63% 2009–2017 (from 8.1% to 13.2%) among young adults 18–25. 

>Serious psychological distress in the last month and suicide-related outcomes (suicidal ideation, plans, attempts, and deaths by suicide) in the last year also increased among young adults 18–25 from 2008–2017 (with a 71% increase in serious psychological distress), with less consistent and weaker increases among adults ages 26 and over. 

>Cultural trends contributing to an increase in mood disorders and suicidal thoughts and behaviors since the mid-2000s, including the rise of electronic communication and digital media and declines in sleep duration, may have had a larger impact on younger people, creating a cohort effect.

While the main findings of the second [article](https://pubmed.ncbi.nlm.nih.gov/24285382/){target="_blank"} are:

>Compared with adult mental health care, the mental health
care of young people has increased more rapidly.

>Between 1995-1998 and 2007-2010, visits resulting in mental disorder diagnoses
per 100 population increased significantly faster for youths (from 7.78 to 15.30 visits) than for
adults (from 23.23 to 28.48 visits) (interaction: P < .001). 

>Psychiatrist visits also increased
significantly faster for youths (from 2.86 to 5.71 visits).


While depression appear to be on the rise for youths, youths also appear to be seeking more mental health care.

In this case study we will evaluate data related to depression episodes and mental health care to evaluate trends overtime. We will be using data from the [National Survey on Drug Use and Health (NSDUH)](https://nsduhweb.rti.org/respweb/homepage.cfm). This data was also used in the first study.  


## **Main Questions**
*** 

#### {.main_question_block}
<b><u> Our main questions: </u></b>

1) How have depression rates in American youth changed since 2002, according to the NSDUH data?  
2) Do mental health services appear to be reaching more youths? How have rates differed between different youth subgroups (gender, ethnicity)?

####

## **Learning Objectives** 
*** 

avocado update these!
<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**It may be a good idea to provide a link to Rstudio's webpage. For the first few months using R, I did not differentiate between R and R Studio. It may be a good distinction to make at least implicitly by providing a link.**

</div>

In this case study, we will determine the percent of youth in America that have had a major depressive episode in the past year since 2002. We will compare how different youth subgroups have changed over time (by age group (12-13,14-15, and 16-17), gender, ethnicity).
We will especially focus on using packages and functions from the [`Tidyverse`](https://www.tidyverse.org/){target="_blank"}, such as [`rvest`](https://github.com/tidyverse/rvest). The tidyverse is a library of packages created by RStudio. While some students may be familiar with previous R programming packages, these packages make data science in R especially efficient.

```{r, out.width = "20%", echo = FALSE, fig.align ="center"}
include_graphics("https://tidyverse.tidyverse.org/logo.png")
```

*** 

We will begin by loading the packages that we will need:

```{r}
library(here)
library(tidyverse)
library(rvest)
```

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**I made some modifications to the table below. The `tidyverse` package hyperlink referenced `readr`. I thought this was incorrect. I changed this to the tidyverse website and provided a different description. If this was indeed a typo, it may need to be fixed in other case studies.**

</div>

 Package   | Use                                                                         
---------- |-------------
[here](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data
[tidyverse](https://www.tidyverse.org/){target="_blank"}      | R packages for data science
[rvest](https://github.com/tidyverse/rvest){target="_blank"}      | to scrape web pages

The first time we use a function, we will use the `::` to indicate which package we are using. Unless we have overlapping function names, this is not necessary, but we will include it here to be informative about where the functions we will use come from.

## **Context**
*** 

According to other sources the rate of suicide has increased for most age groups in the United States over the past decade and a half.

```{r, out.width = "80%", echo = FALSE, fig.align ="center"}
include_graphics("https://www.cdc.gov/nchs/images/databriefs/301-350/db309_fig1.png")
```

#### [[source](https://www.cdc.gov/nchs/products/databriefs/db309.htm)]{target="_blank"}


While suicide does appear to be increasing amoung youths it also appears to be increasing amoung middle aged adults as well for both females and males. 

```{r, out.width = "80%", echo = FALSE, fig.align ="center"}
include_graphics("https://www.cdc.gov/nchs/images/databriefs/301-350/db309_fig2.png")
```

#### [[source](https://www.cdc.gov/nchs/products/databriefs/db309.htm)]{target="_blank"}




```{r, out.width = "80%", echo = FALSE, fig.align ="center"}
include_graphics("https://www.cdc.gov/nchs/images/databriefs/301-350/db309_fig3.png")
```

#### [[source](https://www.cdc.gov/nchs/products/databriefs/db309.htm)]{target="_blank"}


According to the [CDC](https://www.cdc.gov/nchs/products/databriefs/db309.htm){target="_blank"}:

> Since 2008, suicide has ranked as the 10th leading cause of death for all ages in the United States. In 2016, suicide became the **second leading cause of death** among those aged **10–34** and the fourth leading cause among those aged 35–54.




```{r, echo = FALSE, out.width="800px"}
knitr::include_graphics(here::here("img","mortality.png"))
```
#### [[source]](https://www.cdc.gov/nchs/data/databriefs/db293.pdf){target="_blank"}



**So although sucide is on the rise for most age groups, sucide is one of the top two contributors to death for youths.** Thus this warrents further examination of mental health of American youths.


```{r, echo = FALSE, out.width="800px"}
knitr::include_graphics(here::here("img","mortality_age.png"))
```

#### [[source]](https://www.cdc.gov/nchs/data/nvsr/nvsr68/nvsr68_06-508.pdf)



*If you are having thoughts of suicide, please know that you are not alone. If you are in danger of acting on suicidal thoughts, call 911. For support and resources, call the National Suicide Prevention Lifeline at 1-800-273-8255 or text 741-741 for the Crisis Text Line.*

I took this from an article.https://www.theatlantic.com/health/archive/2020/06/why-suicide-rates-among-millennials-are-rising/612943/

*If you or someone you know may be struggling with suicidal thoughts, you can call the U.S. National Suicide Prevention Lifeline at 800-273-TALK (8255) any time day or night, or chat online.*
I thook thos from this article. https://www.usatoday.com/story/news/nation/2020/01/30/u-s-suicide-rate-rose-again-2018-how-can-suicide-prevention-save-lives/4616479002/




covid:https://wellbeingtrust.org/areas-of-focus/policy-and-advocacy/reports/projected-deaths-of-despair-during-covid-19/

Historically, suicide rates were much higher before 1950, however, we are seeing an increase in the last 20 years.

```{r, echo = FALSE, out.width="800px"}
knitr::include_graphics(here::here("img","suicide.png"))
```

#### [[source]](https://time.com/5609124/us-suicide-rate-increase/){target="_blank"}





Besides the US, [other countries](https://academic.oup.com/ije/article/48/5/1650/5366210){target="_blank"} are also experiencing increased reates of depression in youths. See [this report](https://apps.who.int/iris/bitstream/handle/10665/254610/WHO-MSD-MER-2017.2-eng.pdf;jsessionid=E44360055DD83EAC472AA40C2853DBFA?sequence=1){target="_blank"} from the  World Health Organization about rates of depression in other countries.

Great paper about what may be causing increased dpression - and the caveats of if we actually have increased depression: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3330161/




https://www.nimh.nih.gov/health/publications/teen-depression/index.shtml


According to the [National Institute of Mental Health (NIMH)](https://www.nimh.nih.gov/health/publications/teen-depression/index.shtml){target="_blank"}:

If you are in crisis and need help, call this toll-free number for the National Suicide Prevention Lifeline (NSPL), available 24 hours a day, every day: 1-800-273-TALK (8255). The service is available to everyone. The deaf and hard of hearing can contact the Lifeline via TTY at 1-800-799-4889. All calls are confidential. You can also visit the Lifeline’s website at www.suicidepreventionlifeline.org.

The Crisis Text Line is another free, confidential resource available 24 hours a day, seven days a week. Text “HOME” to 741741 and a trained crisis counselor will respond to you with support and information over text message. Visit www.crisistextline.org.


Also see [here](https://www.mhanational.org/depression-teens-0) for more information about how to recognise and help youths experiencing symptoms of depression.

## **Limitations**
*** 

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**Perhaps "underestimates in the p-values..." is not the correct way to phrase this. I would look for a better way to word this.**

</div>

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**Wording for this section should be reviewed.**

</div>

There are some important considerations regarding this data analysis to keep in mind: 

1) We treat sample estimates—estimates of the true population value—as observed values. This produces understimates in the p-values of statistical tests conducted.

2) Furthermore, the sampling mechanism utilized can introduce [selection bias](https://en.wikipedia.org/wiki/Selection_bias?oldformat=true){target="_blank"} in cases where the the [sampling methods do not produce a representative sample](https://en.wikipedia.org/wiki/Sampling_(statistics)?oldformat=true){target="_blank"}. 

3) Data is collected from human participants; this presents the *potential* for information bias, as there is the *potential* that partificipants in the [sampling frame](https://en.wikipedia.org/wiki/Sampling_frame?oldformat=true){target="_blank"} may for a variety of reasons report inaccurate information. 

## **What are the data?**
*** 

We will be using data from the [National Survey on Drug Use and Health (NSDUH)](https://nsduhweb.rti.org/respweb/homepage.cfm){target="_blank"} which is directed by the [Substance Abuse and Mental Health Services Administration (SAMHSA)](https://www.samhsa.gov/){target="_blank"}, an agency in the [U.S. Department of Health and Human Services (DHHS)](https://www.hhs.gov/){target="_blank"}. 

This survey started in 1971 and is conducted annualy in all 50 states and the District of Columbia. Approximately 70,000 people (age 12 and up) are interviewed each year about health realted issues. Households are randomly selected and than a professional interviewer visists the addresses and asks one or two of the residents to inverview. The interviewer brings a laptop with them that the participants use to fill out the survey which typically takes an hour to complete. If a participant chooses to particpate they receive $30 in cash. All collected information is confidential and is used for disease surveillance and to guide public policy particuarlly focused on drug and alcohol use as well as mental health. See [here](https://nsduhweb.rti.org/respweb/about_nsduh.html){target="_blank"} for more details about the survey.

This data is made available publicly online on the [Substance Abuse & Mental Health Data Archive](https://datafiles.samhsa.gov/){target="_blank"}. 

```{r, out.width = "100%", echo = FALSE, fig.align ="center"}
include_graphics(here::here("img", "nsudh_screenshot_webpage.png"))
```

At the [website](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm){target="_blank"} for the survey data, you can see that the results are displayed in many tables. Importantly, there is no obvious way to download the data directly from this particular website.

```{r, out.width = "100%", echo = FALSE, fig.align ="center"}
include_graphics(here::here("img", "website_overview.png"))
```

If one clicks on the TOC botton on the far right upper corner they will be directed to another [website](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetailedTabsTOC2018.htm#toc){target="_blank"}, where a large [pdf document](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetailedTabs2018.pdf){target="_blank"} containing of all of the results can be downloaded.

We are interested in investigating how depression rates have changed and how youths are interacting with mental health services. Thus the following tables are of interest to us are:

Table   | Details                                                                         
---|-------------
Table 11.1A       | Settings Where Mental Health Services Were Received in Past Year among Persons Aged 12 to 17: Numbers in Thousands, 2002-2018   
Table 11.1B       | Settings Where Mental Health Services Were Received in Past Year among Persons Aged 12 to 17: Percentages, 2002-2018  
Table 11.2A       |  Major Depressive Episode in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Numbers in Thousands, 2004-2018
Table 11.2B       | Major Depressive Episode in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Percentages, 2004-2018
Table 11.3A       | Major Depressive Episode with Severe Impairment in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Numbers in Thousands, 2006-2018
Table 11.3B       | Major Depressive Episode with Severe Impairment in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Percentages, 2006-2018
Table 11.4A       | Receipt of Treatment for Depression in Past Year among Persons Aged 12 to 17 with Major Depressive Episode in Past Year, by Demographic Characteristics: Numbers in Thousands, 2004-2018
Table 11.4B       | Receipt of Treatment for Depression in Past Year among Persons Aged 12 to 17 with Major Depressive Episode in Past Year, by Demographic Characteristics: Percentages, 2004-2018


####

## **Data Import**
*** 

Data is often made available online. Usually, the data we are interested in is made available for download on the page as a delimited text file or an excel file. However, sometimes data is not made available in this manner, such as the [NSDUH survey data](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm){target="_blank"}.

How do we proceed in this scenario?

We can manually copy each cell of data, however, this process is often inefficient, subject to error, and not reproducible. Say we wanted to run an analysis next year on the next years data and it happens to be formatted in the same way. 

We can also use `R` for web scraping. 

[Web scraping](https://en.wikipedia.org/wiki/Web_scraping?oldformat=true){target="_blank"} is the process of extracting data from a website.


### Basic steps of web scraping

There are two main steps to web scraping:  

1. Identify location of data on the webpage that will be scraped  

2. Save the webpage element to an object  

We accomplish STEP 1 with our web browser.

We accomplish STEP 2 in the `R` programming environment. 

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**I could not find the animation that I referred to on several occasions.**

**However, I was able to find the sources that I consulted to create the three step `rvest` process. They are included below**

[RStudio](https://rstudio-pubs-static.s3.amazonaws.com/266430_f3fd4660b2744751ab144aa130768a06.html){target="_blank"}

[Blog](http://blog.corynissen.com/2015/01/using-rvest-to-scrape-html-table.html){target="_blank"}

</div>

In this case study we will scrape data from the tables on the [NSDUH survey](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm){target="_blank"} website. This data is available in a large PDF with all the results form the year. However it is not easy to find this PDF and it would be difficult and time consuming to find our tables of interest and to extract the data from the pdf with `pdftools`. Again, if we instead decided to copy paste the data from the website to another file that we would also need to import, this would not be as efficient or reproducible and might result in errors. 


Alternatively, we will use the `rvest` package to [scrape](https://en.wikipedia.org/wiki/Web_scraping?oldformat=true){target="_blank"} the data directly from the tables on the website. Assuming the data next year would be displayed in a similar manner, this could allow us simply modify our code based on the url for the data next year to run the same analysis on the data easily. 

The `rvest`  package can be thought of as the `pdftools` package for webscraping. Upon pulling the data, additional wrangling will likely be required; but like the `pdftools` package, `rvest` streamlines the extraction process.  

### Steps for scraping tables

The two web scraping steps for these tables can be broken down even further: 

1) Identify location of data that will be scraped

+ right-click to inspect element (webpage)
+ hover pointer over components of element (webpage) until the data has been found
+ copy Xpath of data sought

2) Save webpage element to an object in R

+ import html code for the webpage
+ extract pieces of HTML documents (webpage) using Xpath
+ parse the extracted data into a data frame

Below is a animated overview of the process.

```{r, echo = FALSE}
step1 <- image_read(here::here("img", "webpage_screenshot.png"))
step2 <- image_read(here::here("img", "table_screenshot_inspect.png"))
step3 <- image_read(here::here("img", "table_screenshot_inspect_table.png"))
step4 <- image_read(here::here("img", "table_screenshot_inspect_table_xpath.png"))
step5 <- image_read(here::here("img", "table_screenshot_xpath_copy_r.png"))
step5_zoom <- image_read(here::here("img", "table_screenshot_xpath_copy_r_zoom.png"))
```

```{r, eval=FALSE, echo=FALSE}
image_info(step5_zoom)

step5_zoom <- image_border(step5_zoom, "white", "284x334")

img <- c(step1,
         step2,
         step2,
         step3,
         step3,
         step4,
         step4,
         step5,
         step5,
         step5_zoom,
         step5_zoom,
         step5_zoom,
         step1)

educational_gif <- image_resize(img, '1440x900!') %>%
  image_background('white') %>%
  image_morph(frames = 10) %>%
  image_animate(delay = 20,
                optimize = TRUE)

image_write(educational_gif, here::here("img", "educational.gif"))
```

```{r, echo=FALSE}
knitr::include_graphics(here::here("img","educational.gif"))
```

***

Now let's go through each step together:

### 1) Identify location of data that will be scraped

First, let's go to the [web page](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm){target="_blank"} with all the tables we are interested in scraping

```{r, step1, echo=FALSE}
step1
```

Once on the webpage, there aren't any visible options to download the data. 

Right-click and select "Inspect" 

```{r, step2, echo=FALSE}
step2
```

A window opens. 

This window allows us to glance at the internal mechanics of the webpage. To scrape the data from the webpage, we need to first learn a little bit about the components that make it the web page it is. 

Hovering our mouse over the elements of the webpage highlights the respective section of the webpage it represents. By hovering over several elements—and clicking on the elements on the right side of the screen—we can indentify the element that contains the data we are looking for. Another option for identifying xpaths is to use the [selectorgadget tool](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html).  

```{r,step3, echo=FALSE}
step3 
```

Right click on the element and copy the XPath. We will need this XPath for the next step.

```{r, step4, echo=FALSE}
step4
```

Now we can return to the `R` programming environment.

```{r, step5, echo=FALSE}
step5
```

***

### 2) Save webpage element to an object in R 

For the first table we want to scrape, the XPath is `/html/body/div[4]/div[1]/table`. We use this Xpath with functions from the `rvest` package to scrape the data from this table.


```{r,step5_zoom, echo=FALSE}
step5_zoom
```


Let's explore this step in greater detail:

We need to:

+ import html code for the webpage
+ extract pieces (table) out of HTML documents (webpage) using Xpath
+ parse the html table into a data frame

To do this:

+ We import the html code using the `read_html()` function of the `rvest` package
+ We extract specific components of the webpage using the `html_nodes()` function of the `rvest` package
+ We convert this html table into a dataframe using the `html_table()`function of the `rvest` package

**The `rvest` package provides wrappers for the `xml2` and `httr` packages, thus we can just install and load the `rvest` package and it will install and load dependency packages like `xml2` and `httr` and allow us to use functions from  both of these packages.**

In fact, when we load `rvest` the first time we see:

```{r, out.width= "60%"}
knitr::include_graphics(here::here("img", "rvest.png"))
```

In this case, we are scraping table 11.1a from the website. First we assign the url to a character string to use within the `read_html()` function of the `xml2` package. 

```{r}
NSDUH_url <- "https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm"
```

One could also directly use the url but this is less convenient for piping.  

<details> <summary>Click here if you are unfamiliar with piping in R, which uses this `%>%` opperator</summary>  

By [piping](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"} we mean using the `%>%` pipe operator which are usable when loading the tidyverse or several of the packages within the tidyverse like `dplyr` becuase they load the [`magrittr` package](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"}. This allows us to perform multiple sequential steps on one data input.   

</details>  

  
The `read_html()` function then allows us to save the html document for the webpage inside R. 

```{r}
webpage <- NSDUH_url %>%
  xml2::read_html() 
webpage
```

Then we use the `html_nodes()` function of the `rvest` package to select just the table11.1a element of the webpage.

See this [tutorial](http://flukeout.github.io/#){target="_blank"} (and the [answers](https://gist.github.com/chrisman/fcb0a88459cd98239dbe6d2d200b02d1){target="_blank"} in case you get stuck) on CSS selectors to understand more about how this function works to use the `xpath` to select the elements of interest from the webpage.


```{r}
webpage_element <-webpage %>%
  rvest::html_nodes(xpath='/html/body/div[4]/div[1]/table')
webpage_element 

```

Finally, the `html_table()` function of the `rvest` package parses the html object into a data frame.

```{r}
library(dplyr)
table11.1a<-webpage_element%>%
  rvest::html_table()
print(table11.1a, max = 2)
glimpse(table11.1a)
```

We can see that the output is a list with one element, to extract the data from the list we will use brackets `[[]]` to select the first element of the list.
```{r}
table11.1a <- table11.1a[[1]]
```


Putting this all of this together we can do the entire porcess like this with our pipe opperator `%>%`.

```{r}
NSDUH_url <- "https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm"
table11.1a <- NSDUH_url %>%
  xml2::read_html() %>%
  rvest::html_nodes(xpath='/html/body/div[4]/div[1]/table') %>%
  rvest::html_table()
table11.1a <- table11.1a[[1]]
```


Now need to repeat the above process for the other tables we are interested in. 

### Writing a function to scrape multiple tables

We can create a function to accomplish this succinctly. 
Functions allow us to perform the same process on multiple data inputs. See [this other case study](https://opencasestudies.github.io/ocs-bloomberg-vaping-case-study/){target="_blank"} for more details about how to write a function.

In general, the process pf writing functions involves first specifying an input that is used within the function to create an output. In this case the data input is `XPATH` which will be replaced by an actual xpath and the nused in the subsequent steps to scrape the data from each table that an xpath is supplied for.

We will all this function `scarper`.

```{r}
scraper <- function(XPATH){
  NSDUH_url <- "https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm"
  table <- NSDUH_url %>%
  read_html() %>%
  html_nodes(xpath=XPATH) %>%
  html_table()
  output <- table[[1]]
  output
}
```

Now we can apply the function we created to each of the xpaths for each of the tables on the website that we would like to use in our data analysis.

```{r}
table11.1b <- scraper(XPATH = "/html/body/div[4]/div[2]/table")
table11.2a <- scraper(XPATH = '/html/body/div[4]/div[3]/table')
table11.2b <- scraper(XPATH = '/html/body/div[4]/div[4]/table')
table11.3a <- scraper(XPATH = '/html/body/div[4]/div[5]/table')
table11.3b <- scraper(XPATH = '/html/body/div[4]/div[6]/table')
table11.4a <- scraper(XPATH = '/html/body/div[4]/div[7]/table')
table11.4b <- scraper(XPATH = '/html/body/div[4]/div[8]/table')
```


Great! We have successfully scraped the data.

Now we need to wrangle the data.


## **Data Exploration and Wrangling**
*** 

Now that we've imported the data, let's see if we can wrangle a table. Since the data appears to be formated in a similar way in each of the tables, it is likely that whatever steps we take to wrangle this first table will also be necessary in the wrangling of subsequent tables. This is because well-maintained data sources often format different datasets similarly. We can take advantage of this similarity to speed up the wrangling process. 

### **Table11.1a**

First we want to remove the last row of our data frame, which happens to be the legend of our table. Recall from looking at the website that there is a legend for this table.

```{r, echo = FALSE}
knitr::include_graphics(here::here("img", "table11.1a.png"))
```

We can take a look at the last row using the `tail` function of the `dplyr` package. We can specify that we only want to see the last row by using the `n = 1` argument.

```{r}
table11.1a %>%
  dplyr::as_tibble() %>%
  tail(n = 1)
```

We can see that the legend is repeated for every column. Let's take a look at the year 2004 column.
```{r}
table11.1a %>%
  dplyr::as_tibble() %>%  
  select(`2004`) %>%
  tail(n = 1)
```

Let's save this so that we can refer back to it later:
```{r}
legend <- table11.1a %>%
  as_tibble() %>%  
  select(`2004`) %>%
  tail(n = 1)
```

Another way to look at the last row is to use the `n()` function of the `dplyr` package. This function can be used inside other `dplyr` functions and it counts the total number of observations of a group. Within the [`slice()` function](https://dplyr.tidyverse.org/reference/slice.html){target="_blank"} of the `dplyr` packge, it allows you to refer the full length of the object.

```{r}
table11.1a %>%
  dplyr::as_tibble() %>%
  slice(n()) 
```
We can use the `slice()` function of the `dplyr` package to remove this row, by using the `slice`function to select from the first row using `1:` to the second to last row using `n()-1`.

We are also going to use a special pipe opperator from the [`magrittr` package](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"} called the compound assignment pipe-operator or sometimes the double pipe operator. This allows us to use the table11.1a as our input and reasign it at the end after all the steps have been performed.

```{r}
library(magrittr)
table11.1a %<>%
  dplyr::as_tibble() %>%
  slice(1:(n()-1))
```

Now let's take a look at data:
```{r}
table11.1a
```

Great! We can see the the legend is no longer part of the data.

Now let's use the legend to recode the data. There are many different values for missing data, that we would like to replace with `NA` instead.
We can use the `pull()` function of the `dplyr` package to take a look at the legend data:

```{r}
pull(legend, `2004`)
```

Looks like we want to replace values that are: `*`, `--`, `da`, `nc`, and `nr`. We can use the `na_if()` function to recode these values to `NA`.

avocado... there isnt support for doing this in one command... but could at least do two commands



```{r}
table11.1a %<>%
  dplyr::na_if("nc") %>%
  dplyr::na_if("--") %>%
  dplyr::na_if("") %>%
  dplyr::na_if("*")

table11.1a 
```

Now let's rename the first column using the `rename()` function of the `dplyr` package. This requires listing the new name first like so: `new_name = old_name`.
```{r}
table11.1a %<>%
  dplyr::rename(MHS_setting = 
                  `Setting Where Mental Health ServiceWas Received`)
head(table11.1a)
```

Nice!

Now you may notice that the individual values have an `"a"` after the numeric value.

According to the legend this indicates if "the difference between this estimate and the 2018 estimate is significant at the .05 level."

While this is useful information, it makes it difficult to work with our numeric values, so we want to remove them.

Since lower case "a" values occur in the first column values, we want to makes sure we dont remove these.

So how can we do this? We can use the `stringr` package to modify character strings. and we can use the `dplyr` functions `mutate()`, `select()` and `across()` to specify want columns we want to change.

Currently all of our data is of class character as indicated by the `<chr>` under the column names. 

<details> <summary> Click here for an explanation of what a character string is </summary>

There are several classes of data in R programming. Character is one of these classes. 
A chacter string is an individual data value made up of characters. This can be a paragraph, like the legend for the table, or it can be a single letter or number like the letter `"a"` or the number `"3"`. If data is of class character, than the numeric values will not be processed like a numeric value in a mathematical sense. If you want your numeric values to be interpreted that way, they need to be converted to a numeric class. The options typically used are integer (which has no decimal place) and double precision (which has a decimal place). 

</details>

  
The `stringr` package has functions that allow us to replace (the `str_replace()` function) or remove(the `str_remove()` function) characters. 

To use these we need to be able to specify what we want to remove and replace. 

Here is a part of a [cheatsheet](https://rstudio.com/resources/cheatsheets/){target="_blank"} about string manipulation from rstudio.
```{r}
knitr::include_graphics(here::here("img", "regex.png"))
```

We can see that we can refer to any digit (such as 1,2,3 etc.) as `[:digit:]`.
We can also see that we can refer to any punction mark as `[:punct:]`.
Finally, we see that spaces and tabls can be refered to as `[:blank:]`.


If we take a closer look at the first column of our table (using the `pull()` function of the `dplyr` package), we can see that besides the `"a"` values that we see adjacent to our numeric values in the body of the table, we also some large white spaces, some numeric values, instances of `\r\n`, as well as some commas and other punctuation marks. 

```{r}
pull(table11.1a, MHS_setting)
```


We can use the `str_remove_all()` function which is a variant of the `str_remove()` function of the `stringr` package (which allows us to remove all occurences of sepcificed characters in each row rather than just the first occurance, which is what `str_remove()` does), to remove the digit values, the `\r\n` characters and the punctionation marks from the column called `MHS_setting`.

Using the `mutate()` function we specify that we want to change this particular column and replace it with a version of this column that has removed characters that match digits, `r\n` or punctionation marks.

We need to specify that the character strings that should be used can be found ing the `MHS_setting` column by using the `string =` argument and the patterns to find and remove are specified using the `pattern =` argument.

To allow us to look for all three of these patterns at the same time, we can use the `|` symbol between each pattern.


```{r}
table11.1a %<>%
mutate(MHS_setting = 
         str_remove_all(string = MHS_setting, 
                       pattern = "[:digit:]|\r\n|[:punct:]|"))

table11.1a
```

We also want to replace the spaces with an underscore. We can see that sometimes there appears to be more than one space. We can specify that we want any occurance of 1 or more  to be replaced by using the `{1,}` notation.

See here for an explanation of this on the cheat sheet:

```{r}
knitr::include_graphics(here::here("img", "quantifiers.png"))
```

So now we will use the `str_replace_all()` function of the `stringr` package.
In this case we also need to specify a replacement with the `replacement = ` argument.



```{r} 
table11.1a%<>%
mutate(MHS_setting = 
         str_replace_all(string = MHS_setting,
                        pattern = "[:blank:]{1,}", 
                    replacement = "_"))

table11.1a
```

Now to finally remove the "a" values and the commas from the body of the table we can use `str_remove_all()` function yet again. However this time to specify that we want all columns except the first column called `MHS_setting`, we can use the `across()` function of the `dplyr` package. This allows us to specify what columns we want to mutate by using the `.cols = ` argument. We can select all columns except the first column called `MHS_setting` by using a minus sign `-` in front of the column name.



```{r}
table11.1a%<>%
mutate(dplyr::across(.cols = -MHS_setting,
                stringr::str_remove_all, "a|,"))

table11.1a
```

Our table is looking much better!

We also want to change our values to be numeric as opposed to character so that we can use them in mathematical functions. We can use the base `as.numeric()` function. Again we will use the `across()` function to indicate what varaibles we wish to mutate.

```{r}
table11.1a %<>%
  mutate(across(.cols =-MHS_setting, as.numeric))

table11.1a
```

We would also like to add a `type` and `subtype` variable, that specifies the general categories of settings where services were recieved, as well as remove a couple of rows that are completely empty. These are the rows where the first column values are `Genearl_Medicine` and `Juvenile_Justice`, and `Child Welfare`. If we look at the website, we can see that these were leading line with no data.

```{r}
knitr::include_graphics(here::here("img", "table11.1a.png"))
```

First we will add the `type` and `subtype` variables using the `mutate` function.


```{r}
table11.1a %<>%
  mutate(type = c(rep("Specialty", 9), rep("Nonspecialty", 11))) %>%
  mutate(subtype =c("Specialty_total", 
                    rep("Outpatient", 5), 
                    rep("Inpatient", 3), 
                    "Nonspecialty_total", 
                    rep("Education", 3), 
                    rep("General_medicine", 2),
                    rep("Juvenile_Justice", 2),
                    rep("Child_Welfare", 2), 
                    "combination"))

```

We can remove them using the `filter()` function of the `dplyr` package. We can specify that we dont want to keep these rows by using the `!=` not equal to opperator. 


```{r}
table11.1a %<>%
  dplyr::filter(MHS_setting != "General_Medicine") %>%
  dplyr::filter(MHS_setting != "Juvenile_Justice") %>%
  dplyr::filter(MHS_setting != "Child_Welfare")

table11.1a 
```


Finally, we would like to change the shape of our table so that we have a new column that reperesents the year and a new column that represents the value for that year. To do so we will be making our table "longer", meaning that it will have fewer rows and more columns.  See [here](https://en.wikipedia.org/wiki/Wide_and_narrow_data) for more information about different table formats, typically refreed to as wide and long or sometimes narrow.

We will use the `pivot_longer()` function of the `tidyr` package to change the shape of our table. 

There are 3 main arguments in this function:   
1) cols - which specifies what columns to collapse  
2) names_to - which specifies the name of the new column that will be created that will contain the column names of the columns you are collapsing  
3) values_to - which specifies the name of the new column that will be created that will contain the values from the columns you are collapsing 

To specify that we want to collapse all columns except the `MHS_setting` column we can again use the minus sign. Finally, we will make the `Year` variable numeric as well.


```{r}
library(tidyr)
table11.1a %<>%
  tidyr::pivot_longer(cols = contains("20"), 
                  names_to = "Year",
                 values_to = "Number") %>%
  mutate(Year = as.numeric(Year))

table11.1a
```

We can see that our table is now much longer- as we have 289 rows!

#### {.question_block}
<b><u> Question Opportunity </u></b>

Why do we have 289 rows now?

####

Now we see that the `Year` and `Number` variables are of class double because of the `<dbl>` under the column name.

Let's take a look at what the rest of the tables contain:
Table   | Details                                                                         
---|-------------
Table 11.1A       | Settings Where Mental Health Services Were Received in Past Year among Persons Aged 12 to 17: Numbers in Thousands, 2002-2018   
Table 11.1B       | Settings Where Mental Health Services Were Received in Past Year among Persons Aged 12 to 17: Percentages, 2002-2018  
Table 11.2A       |  Major Depressive Episode in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Numbers in Thousands, 2004-2018
Table 11.2B       | Major Depressive Episode in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Percentages, 2004-2018
Table 11.3A       | Major Depressive Episode with Severe Impairment in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Numbers in Thousands, 2006-2018
Table 11.3B       | Major Depressive Episode with Severe Impairment in Past Year among Persons Aged 12 to 17, by Demographic Characteristics: Percentages, 2006-2018
Table 11.4A       | Receipt of Treatment for Depression in Past Year among Persons Aged 12 to 17 with Major Depressive Episode in Past Year, by Demographic Characteristics: Numbers in Thousands, 2004-2018
Table 11.4B       | Receipt of Treatment for Depression in Past Year among Persons Aged 12 to 17 with Major Depressive Episode in Past Year, by Demographic Characteristics: Percentages, 2004-2018

OK, so the next table is very similar to Table11.1A, while the remaining tables have information about demographics.




As a reminder here are all of the steps that we performed to wrangle `table11.1a`:



```{r, eval = FALSE}
table11.1a %<>%
  dplyr::as_tibble() %>%
  slice(1:(n()-1))%>%
  dplyr::na_if("nc") %>%
  dplyr::na_if("--") %>%
  dplyr::na_if("") %>%
  dplyr::na_if("*")%>%
  dplyr::rename(MHS_setting = 
                  `Setting Where Mental Health ServiceWas Received`) %>%
  mutate(MHS_setting = 
         str_remove_all(string = MHS_setting, 
                       pattern = "[:digit:]|\r\n|[:punct:]|")) %>%
  mutate(MHS_setting = 
         str_replace_all(string = MHS_setting,
                        pattern = "[:blank:]{1,}", 
                    replacement = "_")) %>%
  mutate(dplyr::across(.cols = -MHS_setting,
                stringr::str_remove_all, "a|,")) %>%
  mutate(across(-MHS_setting, as.numeric)) %>%
  mutate(type = c(rep("Specialty", 9), rep("Nonspecialty", 11))) %>%
  mutate(subtype =c("Specialty_total", 
                    rep("Outpatient", 5), 
                    rep("Inpatient", 3), 
                    "Nonspecialty_total", 
                    rep("Education", 3), 
                    rep("General_medicine", 2),
                    rep("Juvenile_Justice", 2),
                    rep("Child_Welfare", 2), 
                    "combination")) %>%
  dplyr::filter(MHS_setting != "General_Medicine") %>%
  dplyr::filter(MHS_setting != "Juvenile_Justice") %>%
  dplyr::filter(MHS_setting != "Child_Welfare") %>%
    tidyr::pivot_longer(cols = contains("20"), 
                  names_to = "Year",
                 values_to = "Number") %>%
   mutate(Year = as.numeric(Year))
```

Now we want to wrangle table11.1B which is formatted the most similarly. To do so we can simply run these steps on the using the `table11.1B` as the input. For the sake of education however, we will show you how you could make a function if we had several more similar tables to wrangle. This will also make it easier to write a function to wrangle the other demographic tables.

Last time we wrote a function in this case study, we only had one input in our function. This time we will have several inputs. We will have the table that we want to wrangle as `TABLE`, a new name for the first column called `new_col`, and an input called `pivot_col` which will be the name of the column that will be created after pivoting that will take the values from each of the years.

We will also add code to remove all rows that have only NA values, this means we don't need to know what rows ahead of time.

To do this we will use the `filter()` and `select()` functions of the `dplyr` package. 

We will calculate a sum of the count of `NA` values across the rows for the numeric columns (the columns for each year) using the base `rowSums()` fuction.

To do this we first select the columns that are numeric using: `select(., is.numeric)`, where the `.` refers to the table after all the previous wrangling steps in our function.

Then we get a true or false statement about which columns have na values with the base `is.na()` function (this requires numeric values).


Then we caculate the sum using the base `rowSums()` function.


Altogether this looks like this: `rowSums(is.na(select(., is.numeric)))`.
Finally we compare this to the number of columns that are numeric by using: `length(select(., is.numeric)))`, with the idea that if the number of `NA` values is less than the number of columns that could have `NA` values, then we know it is not an empty row.
              
Note that if we were using the `summarise()` or `mutate()` function or the `dplyr` package, then we could use the `across()` function of the `dplyr` package to select what columns we wanted to use in our calculation.


```{r}
data_prep_settings <- function(TABLE, new_col, pivot_col){
  dplyr::as_tibble(TABLE) %>%
  slice(1:(n()-1))%>%
  na_if("nc") %>%
  na_if("--") %>%
  na_if("") %>%
  na_if("*") %>%
    rename({{new_col}} := names(.)[1]) %>%
     mutate({{new_col}} := 
         str_remove_all(string = pull(., {{new_col}}), 
                       pattern = "[:digit:]|\r\n|[:punct:]|")) %>%
  mutate({{new_col}} := 
         str_replace_all(string =pull(., {{new_col}}),
                        pattern = "[:blank:]{1,}", 
                    replacement = "_")) %>%
  mutate(dplyr::across(.cols = -{{new_col}},
                stringr::str_remove_all, "a|,")) %>%
     mutate(across(-{{new_col}}, as.numeric)) %>%
    mutate(type = c(rep("Specialty", 9), rep("Nonspecialty", 11))) %>%
     mutate(subtype =c("Specialty_total", 
                    rep("Outpatient", 5), 
                    rep("Inpatient", 3), 
                    "Nonspecialty_total", 
                    rep("Education", 3), 
                    rep("General_medicine", 2),
                    rep("Juvenile_Justice", 2),
                    rep("Child_Welfare", 2), 
                    "combination")) %>%
     filter(rowSums(is.na(select(., is.numeric))) <
              length(select(., is.numeric))) %>%
  pivot_longer(cols = contains("20"), 
               names_to = "Year", 
               values_to = pivot_col)%>%
     mutate(Year = as.numeric(Year))
}
```

Now we can apply the function to `table11.1b`.

### **Table11.1b**

```{r}
table11.1b<- data_prep_settings(
                    TABLE = table11.1b,
                  new_col = "MHS_setting",
                pivot_col = "Percent")

table11.1b
```

Great!

What about the subsequent tables?

### **Demographic Tables**

All of the rest of the tables have demographic information and have this general structure:

```{r}
knitr::include_graphics(here::here("img", "dem_table.png"))
```

In these tables we have age groups in our first column so we dont want to remove digits or punctuation marks anymore so we need to modify our function a bit to remove that step. 

We also want to add the word `Age` and an underscore in front of the age group listed in the tables. We can use the `str_replace()` function of the `stringr` package, becuase now we want to only replace the first instance of `1` with `Age_1`.

We also plan to replace the first column name with `Demographic` for all of the tables.

We also want to create a new variable that list the subgroups.

We will also split the function into two so that we can check how the data looks as we expect before we change the shape of the table. We will call the function that performs `pivot_longer()` step `Make_long()`.



```{r}
data_dem_settings <- function(TABLE){
  dplyr::as_tibble(TABLE) %>%
  slice(1:(n()-1))%>%
  na_if("nc") %>%
  na_if("--") %>%
  na_if("") %>%
  na_if("*") %>%
    rename(Demographic := names(.)[1]) %>%
  mutate(Demographic := 
         str_replace_all(string =pull(., Demographic),
                        pattern = "[:blank:]{1,}", 
                    replacement = "_")) %>%
  mutate(Demographic = str_replace(string = Demographic, 
                                  pattern = "1", 
                              replacement = "Age_1")) %>%
 mutate(subgroup =c("Total",
                    rep("Age", 4), 
                    rep("Sex", 3), 
                    rep("Race", 9)))%>%
  mutate(dplyr::across(.cols = contains("20"),
                stringr::str_remove_all, "a|,")) %>%
     mutate(across(contains("20"), as.numeric)) %>%
     filter(rowSums(is.na(select(., is.numeric))) <
              length(select(., is.numeric)))}

Make_long <-function(TABLE, pivot_col){
  TABLE %>%
  pivot_longer(cols = contains("20"), 
               names_to = "Year", 
               values_to = pivot_col)%>%
     mutate(Year = as.numeric(Year))}
```

from Michael

```{r, eval=FALSE, echo=FALSE}
data_prep_dem <- function(TABLE, old_col, new_col, pivot_col){
  TABLE <- TABLE[-dim(TABLE)[1],]
  TABLE <- TABLE %>%
  na_if("nc") %>%
  na_if("--") %>%
  na_if("") %>%
  na_if("*")
  TABLE <- TABLE %>%
    as_tibble() %>%
    rename({{new_col}} := {{old_col}})
  partA <- TABLE %>%
    dplyr::select({{new_col}})
  partB <- TABLE %>%
    dplyr::select(-{{new_col}})
  partA <- partA %>%
  mutate({{new_col}} := partA %>%
           dplyr::select({{new_col}}) %>%
           pull({{new_col}}) %>%
           gsub("[\r\n]|[[:punct:]]|([[:blank:]])\\1+",
                        "", .))
  partA <- partA %>%
  mutate({{new_col}} := dplyr::case_when(stringr::str_detect(!!base::as.name(new_col), pattern = "1") ~ base::paste("Age",
                                                        stringr::str_sub(!!base::as.name(new_col),
                                                                start = 1,
                                                                end =2),
                                                        stringr::str_sub(!!base::as.name(new_col),
                                                                start = 3,
                                                                end = 4),
                                                        sep="_"),
                                 TRUE ~ !!base::as.name(new_col)))
  partB <- partB %>%
    mutate(across(.cols = everything(),
                str_remove_all, "a")) %>%
    mutate(across(.cols = everything(),
                str_remove_all, ","))
  rm(TABLE)
  TABLE <- bind_cols(partA,
                     partB)
  TABLE <- TABLE %>%
  pivot_longer(cols = contains("20"), names_to = "Year", values_to = pivot_col)
  TABLE
}
```



We use the function to wrangle the next pair of tables. 
```{r}
table11.2a <- data_dem_settings(TABLE = table11.2a)

glimpse(table11.2a)

table11.2b <- data_dem_settings(TABLE = table11.2b)

glimpse(table11.2b)

table11.3a <- data_dem_settings(TABLE = table11.3a)

glimpse(table11.3a)

table11.3b <- data_dem_settings(TABLE = table11.3b)

glimpse(table11.3b)

table11.4a <- data_dem_settings(TABLE = table11.4a)

glimpse(table11.4a)

table11.4b <- data_dem_settings(TABLE = table11.4b)

glimpse(table11.4b)

```

```{r}
table11.2a <-table11.2a %>% Make_long(pivot_col = "Number")
table11.3a <-table11.3a %>% Make_long(pivot_col = "Number")
table11.4a <-table11.4a %>% Make_long(pivot_col = "Number")

table11.2b <-table11.2b %>% Make_long(pivot_col = "Percent")
table11.3b <-table11.3b %>% Make_long(pivot_col = "Percent")
table11.4b <-table11.4b %>% Make_long(pivot_col = "Percent")
```

We can now use the functions to wrangle the remaining tables. 

```{r, eval = FALSE}
tables <- list(table11.2a = table11.2a, table11.2b = table11.2b, 
               table11.3a = table11.3a, table11.3b = table11.3b, 
               table11.4a = table11.4a, table11.4b = table11.4b)

remaining_tables <-map_df(tables, data_dem_settings)
remaining_tables


count_tables <- list(table11.2a = table11.2a, 
                     table11.3a = table11.3a,
                     table11.4a = table11.4a)

percent_tables <- list(table11.2b = table11.2b, 
                       table11.3b = table11.3b,
                       table11.4b = table11.4b)

count_tables<-map_df(count_tables, data_dem_settings)

map(~count_tables, Make_long(TABLE = ., pivot_col = "Number"))
```

Now let's change the format of all of these tables.


from Michael
```{r, echo = FALSE, eval = FALSE}
dim(table11.2a)

table11.2a <- data_prep_dem(TABLE = table11.2a,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
        pivot_col = "Number")

table11.2a %>%
  filter(!complete.cases(.)) %>%
  dplyr::group_by(Demographic) %>%
  tally()

table11.2a <- table11.2a %>%
  filter(stats::complete.cases(.) | Demographic == "AIAN")

table11.2a <- table11.2a %>%
  mutate(across(c(Year, Number), as.numeric))
```

### **Table11.2b**

```{r, eval = FALSE}
dim(table11.2b)

table11.2b <- data_prep_dem(TABLE = table11.2b,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Percent")

table11.2b %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.2b <- table11.2b %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.2b <- table11.2b %>%
  mutate(across(c(Year, Percent), as.numeric))
```

We repeat this process for the remaining tables.



### **Table 11.3a**

```{r, eval = FALSE}
dim(table11.3a)

table11.3a <- data_prep_dem(TABLE = table11.3a,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Number")

table11.3a %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.3a <- table11.3a %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.3a <- table11.3a %>%
  mutate(across(c(Year, Number), as.numeric))
```


### **Table 11.3b**

```{r, eval=FALSE}
dim(table11.3b)

table11.3b <- data_prep_dem(TABLE = table11.3b,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Percent")

table11.3b %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.3b <- table11.3b %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.3b <- table11.3b %>%
  mutate(across(c(Year, Percent), as.numeric))
```



### **Table 11.4a**

```{r, eval = FALSE}
dim(table11.4a)

table11.4a <- data_prep_dem(TABLE = table11.4a,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Number")

table11.4a %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.4a <- table11.4a %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.4a <- table11.4a %>%
  mutate(across(c(Year, Number), as.numeric))
```



### **Table 11.4b**

```{r, eval =FALSE}
dim(table11.4b)

table11.4b <- data_prep_dem(TABLE = table11.4b,
          old_col = "Demographic Characteristic",
          new_col = "Demographic",
          pivot_col = "Percent")

table11.4b %>%
  filter(!complete.cases(.)) %>%
  group_by(Demographic) %>%
  tally()

table11.4b <- table11.4b %>%
  filter(complete.cases(.) | Demographic == "AIAN")

table11.4b <- table11.4b %>%
  mutate(across(c(Year, Percent), as.numeric))
```

Now that we've wrangled the data, we can go ahead and proceed with our analysis. 

## **Data Analysis**
*** 

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**In this section, we only analyzed data from tables 2-4. Data from table 1 is very different than data from tables 2-4. For expediency, I did not include an example with data frome table 1. The following code, however, can easily be repurposed to accomplish that once a specific group has been identified to conduct the test on.**

</div>

We would like to conduct a [chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test?oldformat=true) for independence. 

To conduct this statistical test, we need to produce a 2x2 table.

The following code subsets the data we need and makes the necessary manipulations so that the units of observation are appropriate. 

```{r}
chi_square_11.2a <- table11.2a %>%
  filter(Year %in% c(2009, 2018)) %>%
  filter(Demographic %in% c("Male","Female")) %>%
  mutate(Number = Number * 1000)
```

The resulting object is still in long format.

```{r}
chi_square_11.2a
```

To conduct a chi-squared test for indepence we will need a [contingency table](https://en.wikipedia.org/wiki/Contingency_table?oldformat=true). 

A contingency table can be produced from data in long format by transforming the data to wide format and repurposing some values as row names. 

```{r}
chi_square_11.2a <- chi_square_11.2a %>%
  tidyr::pivot_wider(id_cols = -subgroup,
                     names_from = Year,
              names_prefix = "Year", 
              values_from = Number) %>%
  tibble::column_to_rownames("Demographic")
```

The final object should look like this. 

```{r}
chi_square_11.2a
```

The chi-squared test for independence can be conducted using the `stats::chisq.test()` function. 

```{r}
stats::chisq.test(chi_square_11.2a)
```

We can repeat this process for the remaining tables.

```{r}
chi_square_11.3a <- table11.3a %>%
  filter(Year %in% c(2009, 2018)) %>%
  filter(Demographic %in% c("Male","Female")) %>%
  mutate(Number = Number * 1000)

chi_square_11.3a <- chi_square_11.3a %>%
  pivot_wider(id_cols = -subgroup,
              names_from = Year,
              names_prefix = "Year", 
              values_from = Number) %>%
  column_to_rownames("Demographic")

chi_square_11.3a
```

```{r}
chisq.test(chi_square_11.3a)
```

```{r}
chi_square_11.4a <- table11.4a%>%
  filter(Year %in% c(2009, 2018)) %>%
  filter(Demographic %in% c("Male","Female")) %>%
  mutate(Number = Number * 1000)

chi_square_11.4a <- chi_square_11.4a %>%
  pivot_wider(id_cols = -subgroup,
              names_from = Year,
              names_prefix = "Year", 
              values_from = Number) %>%
  column_to_rownames("Demographic")

chi_square_11.4a
```

```{r}
chisq.test(chi_square_11.4a)
```

## **Data Visualization**
*** 

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**This is the intentionally terrible plot that requires faceting.**
https://community.rstudio.com/t/unique-legends-in-facet-grid/49195

</div>


Need to filter for sertain types and then split into two plots...
```{r}
library(directlabels)
plotMHS <-table11.1b %>%
  ggplot2::ggplot(aes(x = Year, y = Percent, group = MHS_setting, color = MHS_setting)) +
  ggplot2::geom_line() +
  facet_wrap(~type)+
  ggplot2::scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  ggplot2::labs(title = "Settings Where Mental Health Services Were Received in Past Year\namong Persons Aged 12 to 17",
       subtitle = "Percentages, 2002-2018")

directlabels::direct.label(plotMHS, method = list("angled.boxes"))
```

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**The plots below need to be correctly faceted. Keep in mind that tables 11.2+ must be faceted by demographic group type and not by setting type.**

</div>

```{r}
table11.1b %>%
  ggplot(aes(x = Year, y = Percent, group = MHS_setting)) +
  geom_line() +
  facet_wrap(~type) +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  labs(title = "Settings Where Mental Health Services Were Received in Past Year\namong Persons Aged 12 to 17",
       subtitle = "Percentages, 2002-2018")
```

https://stackoverflow.com/questions/14840542/place-a-legend-for-each-facet-wrap-grid-in-ggplot2
option using cowplot:
 make list of plots
ggList <- lapply(split(x, x$Server), function(i) {
  ggplot(i, aes(Date, PercentUsed, group = 1, colour = FileSystem)) + 
    geom_jitter(size = 2) +
    geom_smooth(method = "loess", se = TRUE)})

 plot as grid in 1 columns
cowplot::plot_grid(plotlist = ggList, ncol = 1,
                   align = 'v', labels = levels(x$Server))
                   
library(gridExtra)

xs <- split(x,f = x$Server)
p1 <- ggplot(xs$A,aes(x = Date,y = PercentUsed,group = 1,colour = FileSystem)) + 
        geom_jitter(size=0.5) + 
        geom_smooth(method="loess", se=T) + 
        facet_wrap(~Server, ncol=1)

p2 <- p1 %+% xs$B
p3 <- p1 %+% xs$C

grid.arrange(p1,p2,p3)                   
```{r}
table11.2b %>%
  ggplot(aes(x = Year, y = Percent, group = Demographic, color =Demographic)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  labs(title = "Major Depressive Episode in Past Year\namong Persons Aged 12 to 17",
       subtitle = "By Demographic Characteristics, Percentages, 2004-2018") +
  facet_wrap(~subgroup)
```

```{r}
table11.2b %>%
  filter(Demographic %in% c("Age_12-13", "Age_14-15", "Age_16-17")) %>%
  ggplot(aes(x = Year, y = Percent, group = Demographic)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  labs(title = "Major Depressive Episode in Past Year\namong Persons Aged 12 to 17",
       subtitle = "By Demographic Characteristics, Percentages, 2004-2018")
```

```{r}
table11.3b %>%
  ggplot(aes(x = Year, y = Percent, group = Demographic)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) +
  labs(title = "Major Depressive Episode with Severe Impairment in Past Year\namong Persons Aged 12 to 17",
       subtitle = "By Demographic Characteristics: Percentages, 2006-2018")
```

```{r}
table11.4b %>%
  ggplot(aes(x = Year, y = Percent, group = Demographic)) +
  geom_line() +
  scale_x_continuous(breaks = seq(2009, 2018, by=1),
                     labels = seq(2009, 2018, by=1),
                     limits = c(2009, 2018)) + 
  labs(title = "Receipt of Treatment for Depression in Past Year among\nPersons Aged 12 to 17 with Major Depressive Episode in Past Year",
       subtitle = "By Demographic Characteristics: Percentages, 2004-2018")
```

<style>
div.red { background-color:#FFE6E6; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">

**The plots created (after faceting properly) can be used to answer the questions listed at the beginning of the case study. After finalizing the plots, some time should be spent towards framing the visualizations in such a way to underscore how they were used to asnwer the question.**

</div>

## **Summary**
*** 

## **Suggested Homework**
*** 

## **Additional Information**
***

### Helpful Links


**This needs to be updated**

[guide](https://briatte.github.io/ggcorr/) for using GGally to create correlation plots

<u>Terms and concepts covered:</u>  

[Tidyverse](https://www.tidyverse.org/){target="_blank"}  
[RStudio cheatsheets](https://rstudio.com/resources/cheatsheets/){target="_blank"}  

<u>Packages used in this case study: </u>

 Package   | Use                                                                         
---------- |-------------
[here](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data 
[tidyverse](https://www.tidyverse.org/){target="_blank"}      | R packages for data science
[rvest](https://github.com/tidyverse/rvest){target="_blank"}      | to scrape web pages


### Acknowledgements

We would like to acknowledge [Tamar Mendelson](https://www.jhsph.edu/faculty/directory/profile/1770/tamar-mendelson) for assisting in framing the major direction of the case study.

We would also like to acknowledge the [Bloomberg American Health Initiative](https://americanhealth.jhu.edu/) for funding this work. 


### **RA Notes**

[This is the motivating article for this case study](https://pubmed.ncbi.nlm.nih.gov/30869927/). In this article, they web scrape to obtain the data they need. 

[Here is the Lieber Institute's resource on web scrape](http://research.libd.org/rstatsclub/post/introduction-to-scraping-and-wranging-tables-from-research-articles/#.Xw878ZNKhQJ)

[Here is a resouce the Lieber Institute source above referse to](http://blog.corynissen.com/2015/01/using-rvest-to-scrape-html-table.html)

[Here as a good resource to learn how to web scrape](https://rstudio-pubs-static.s3.amazonaws.com/266430_f3fd4660b2744751ab144aa130768a06.html)

[This is the set of tables we would like to consider](https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHDetailedTabs2018R2/NSDUHDetTabsSect11pe2018.htm)
